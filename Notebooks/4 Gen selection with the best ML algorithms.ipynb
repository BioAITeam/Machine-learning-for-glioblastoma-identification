{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00f6332",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b75ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Methods\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from yellowbrick.classifier import ClassificationReport \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "#Tools\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "import string \n",
    "import time as tm\n",
    "import os\n",
    "from scipy.sparse import csr_matrix \n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "\n",
    "#Class balance\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids \n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae6147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be25a55b",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862ba576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_metrics(X_train,X_test,y_train,y_test,HO=True,CV=True):    \n",
    "    def metrics(model):\n",
    "        if HO == True:\n",
    "            print(\"\\nHold-Out in process...\")\n",
    "            start_time = tm.time()\n",
    "            model.fit(X_train, y_train) \n",
    "            TIME = tm.time() - start_time \n",
    "            print(\"Time, Training: {0:.4f} [seconds]\".format(TIME))\n",
    "            start_time = tm.time()\n",
    "            y_pred = model.predict(X_test)\n",
    "            TIME = tm.time() - start_time \n",
    "            print(\"Time, Prediction: {0:.4f} [seconds]\".format(TIME))\n",
    "\n",
    "            accuracy_s  = accuracy_score(y_test,y_pred) \n",
    "            print('accuracy_score: {0:.4f}'.format(accuracy_s))\n",
    "            f1_s        = f1_score(y_test,y_pred,average='weighted')\n",
    "            print('f1_score: {0:.4f}'.format(f1_s))\n",
    "            recall_s    = recall_score(y_test,y_pred,average='weighted')\n",
    "            print('recall_score: {0:.4f}'.format(recall_s))\n",
    "            precision_s = precision_score(y_test,y_pred,average='weighted')\n",
    "            print('precision_score: {0:.4f}'.format(precision_s))\n",
    "\n",
    "            if type(list(np.unique(np.array(y_train)))[0]).__name__ == 'str': #If the classes are categorical with string names\n",
    "                le           = LabelEncoder() \n",
    "                le.fit(list(np.unique(np.array(y_train)))) \n",
    "                y_test_coded = le.transform(y_test) \n",
    "                y_pred_coded = le.transform(y_pred) \n",
    "                mse_s        = MSE(y_test_coded,y_pred_coded)\n",
    "                print('MSE: {0:.4f}'.format(mse_s))\n",
    "            else:\n",
    "                mse_s        = MSE(y_test,y_pred)\n",
    "                print('MSE: {0:.4f}'.format(mse_s))\n",
    "\n",
    "            if len(list(np.unique(np.array(y_train)))) > 2: #For multiclass classification, more than 2 classes\n",
    "                y_pred_proba = model.predict_proba(X_test)[:]\n",
    "                roc_s        = roc_auc_score(y_test, y_pred_proba, multi_class='ovo', average='weighted')\n",
    "                print('ROC_AUC: {0:.4f}'.format(roc_s))            \n",
    "            else:\n",
    "                y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "                roc_s        = roc_auc_score(y_test, y_pred_proba, multi_class='ovo', average='weighted')\n",
    "                print('ROC_AUC: {0:.4f}'.format(roc_s))\n",
    "\n",
    "            ck_s         = cohen_kappa_score(y_test,y_pred)\n",
    "            print('CK: {0:.4f}'.format(ck_s))\n",
    "        \n",
    "        if CV == True:\n",
    "            print('\\nCross-Validation in process...')\n",
    "            start_time = tm.time() \n",
    "            kfold = model_selection.KFold(n_splits=10)\n",
    "            y_CV = np.concatenate((y_train,y_test))\n",
    "            if \"GaussianNB\" in str(name) or \"LinearDiscriminantAnalysis\" in str(name) or \"QuadraticDiscriminantAnalysis\" in str(name):\n",
    "                X_CV = np.concatenate((X_train,X_test))\n",
    "                cv_results = np.array(model_selection.cross_val_score(model, X_CV, y_CV, cv=kfold, scoring='accuracy', n_jobs=-3))\n",
    "            else:\n",
    "                X_CV = np.concatenate((X_train.toarray(),X_test.toarray()))\n",
    "                X_CV = csr_matrix(X_CV)\n",
    "                cv_results = np.array(model_selection.cross_val_score(model, X_CV, y_CV, cv=kfold, scoring='accuracy', n_jobs=-3))\n",
    "\n",
    "            cv_results = cv_results[np.logical_not(np.isnan(cv_results))] \n",
    "            TIME = tm.time() - start_time \n",
    "            print(\"Time, CV: {0:.4f} [seconds]\".format(TIME))\n",
    "            print('CV: {0:.4f} {1:.4f}'.format(cv_results.mean(),cv_results.std()))\n",
    "\n",
    "    for name in classifiers:\n",
    "        print (\"---------------------------------------------------------------------------------\\n\") \n",
    "        print(str(name))\n",
    "        if \"GaussianNB\" in str(name) or \"LinearDiscriminantAnalysis\" in str(name) or \"QuadraticDiscriminantAnalysis\" in str(name):\n",
    "            X_train=csr_matrix(X_train) \n",
    "            X_test =csr_matrix(X_test) \n",
    "            X_train=X_train.toarray() \n",
    "            X_test=X_test.toarray() \n",
    "        else:\n",
    "            X_train=csr_matrix(X_train)\n",
    "            X_test=csr_matrix(X_test)\n",
    "            \n",
    "        metrics(name)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d9d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balance_over_sampling(features, labels, HO=False, CV=True, methods_list=[\"RandomOverSampler\"]):\n",
    "    \n",
    "    best_acc=list()\n",
    "    for method in methods_list:\n",
    "        if method == \"RandomOverSampler\":\n",
    "            print(method)\n",
    "            print(\"originals labels unique: \",np.unique(labels, return_counts=True)) \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                                test_size=0.20, random_state=21, stratify=labels)\n",
    "            sampler = RandomOverSampler(random_state=21) \n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)             \n",
    "            print(\"y_train labels unique:   \",np.unique(y_train, return_counts=True))\n",
    "            print(\"y_test labels unique:    \",np.unique(y_test, return_counts=True)) \n",
    "            classifier_metrics(X_train,X_test,y_train,y_test,HO=HO,CV=CV)\n",
    "            \n",
    "        elif method == \"SMOTE\":\n",
    "            print(method)\n",
    "            print(\"originals labels unique: \",np.unique(labels, return_counts=True)) \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                                test_size=0.20, random_state=21, stratify=labels)\n",
    "            sampler = SMOTE(random_state=21,n_jobs=-1) \n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)             \n",
    "            print(\"y_train labels unique:   \",np.unique(y_train, return_counts=True))\n",
    "            print(\"y_test labels unique:    \",np.unique(y_test, return_counts=True)) \n",
    "            classifier_metrics(X_train,X_test,y_train,y_test,HO=HO,CV=CV)\n",
    "\n",
    "        elif method == \"SMOTEN\":\n",
    "            print(method)\n",
    "            print(\"originals labels unique: \",np.unique(labels, return_counts=True)) \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                                test_size=0.20, random_state=21, stratify=labels)\n",
    "            sampler = SMOTEN(random_state=21,n_jobs=-1)\n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)             \n",
    "            print(\"y_train labels unique:   \",np.unique(y_train, return_counts=True))\n",
    "            print(\"y_test labels unique:    \",np.unique(y_test, return_counts=True)) \n",
    "            classifier_metrics(X_train,X_test,y_train,y_test,HO=HO,CV=CV)\n",
    "            \n",
    "        elif method == \"ADASYN\":\n",
    "            print(method)\n",
    "            print(\"originals labels unique: \",np.unique(labels, return_counts=True)) \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                                test_size=0.20, random_state=21, stratify=labels)\n",
    "            sampler = ADASYN(random_state=21,n_jobs=-1) \n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)             \n",
    "            print(\"y_train labels unique:   \",np.unique(y_train, return_counts=True))\n",
    "            print(\"y_test labels unique:    \",np.unique(y_test, return_counts=True)) \n",
    "            classifier_metrics(X_train,X_test,y_train,y_test,HO=HO,CV=CV)\n",
    "            \n",
    "        elif method == \"BorderlineSMOTE\":\n",
    "            print(method)\n",
    "            print(\"originals labels unique: \",np.unique(labels, return_counts=True)) \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                                test_size=0.20, random_state=21, stratify=labels)\n",
    "            sampler = BorderlineSMOTE(random_state=21,n_jobs=-1) \n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)             \n",
    "            print(\"y_train labels unique:   \",np.unique(y_train, return_counts=True))\n",
    "            print(\"y_test labels unique:    \",np.unique(y_test, return_counts=True)) \n",
    "            classifier_metrics(X_train,X_test,y_train,y_test,HO=HO,CV=CV)\n",
    "            \n",
    "        elif method == \"KMeansSMOTE\":\n",
    "            print(method)\n",
    "            print(\"originals labels unique: \",np.unique(labels, return_counts=True)) \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                                test_size=0.20, random_state=21, stratify=labels)\n",
    "            sampler = KMeansSMOTE(random_state=21,n_jobs=-1, k_neighbors=np.unique(y_test).shape[0]) \n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)             \n",
    "            print(\"y_train labels unique:   \",np.unique(y_train, return_counts=True))\n",
    "            print(\"y_test labels unique:    \",np.unique(y_test, return_counts=True)) \n",
    "            classifier_metrics(X_train,X_test,y_train,y_test,HO=HO,CV=CV)\n",
    "            \n",
    "        elif method == \"SVMSMOTE\":\n",
    "            print(method)\n",
    "            print(\"originals labels unique: \",np.unique(labels, return_counts=True)) \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                                test_size=0.20, random_state=21, stratify=labels)\n",
    "            sampler = SVMSMOTE(random_state=8,n_jobs=-1) \n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)             \n",
    "            print(\"y_train labels unique:   \",np.unique(y_train, return_counts=True))\n",
    "            print(\"y_test labels unique:    \",np.unique(y_test, return_counts=True)) \n",
    "            classifier_metrics(X_train,X_test,y_train,y_test,HO=HO,CV=CV)\n",
    "            \n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_complete_s1(path):\n",
    "    df_complete=pd.read_csv(path)\n",
    "    \n",
    "    # Scenario 1: Tumor_Core & Tumor_Periphery\n",
    "    # Se procede a eliminar el N_Periphery\n",
    "\n",
    "    df2 = df_complete.copy()\n",
    "    df2.drop(df2[df2.classes == \"NP\"].index, inplace=True)  \n",
    "    \n",
    "    # Eliminamos los labels\n",
    "    features = df2.copy()\n",
    "    features = features.drop(['classes'], axis=1)\n",
    "    \n",
    "    #Extraemos los labels\n",
    "    labels = df2.copy()\n",
    "    labels = labels['classes'].values\n",
    "    \n",
    "    return features,labels\n",
    "\n",
    "def load_data_complete_s2(path):\n",
    "    df_complete=pd.read_csv(path)\n",
    "    \n",
    "    # Scenario 2: Normal_Periphery & Tumor_Periphery\n",
    "    # Se procede a eliminar el T_Core\n",
    "\n",
    "    df2 = df_complete.copy()\n",
    "    df2.drop(df2[df2.classes == \"TC\"].index, inplace=True)  \n",
    "    \n",
    "    # Eliminamos los labels\n",
    "    features = df2.copy()\n",
    "    features = features.drop(['classes'], axis=1)\n",
    "    \n",
    "    #Extraemos los labels\n",
    "    labels = df2.copy()\n",
    "    labels = labels['classes'].values\n",
    "    \n",
    "    return features,labels\n",
    "\n",
    "def load_data_complete_s3(path):\n",
    "    df_complete=pd.read_csv(path)\n",
    "    # Scenario 3: Tumor_Periphery&Core & Normal_Periphery\n",
    "    \n",
    "    # Se procede aislar al N_Periphery\n",
    "    df2 = df_complete.copy()\n",
    "    df2.drop(df2[df2.classes == \"TP\"].index, inplace=True)  \n",
    "    df2.drop(df2[df2.classes == \"TC\"].index, inplace=True)  \n",
    "    \n",
    "    # Eliminamos el N_Periphery\n",
    "    df3 = df_complete.copy()\n",
    "    df3.drop(df3[df3.classes == \"NP\"].index, inplace=True) \n",
    "    \n",
    "    # y luego se procede a renombrar la columna classes con T_PC, al quedar la unión de estas\n",
    "    df3[\"classes\"] = \"TPC\"\n",
    "    \n",
    "    # Se procede a crear el DF ya con las clases que corresponde al Escenario 3: Tumor_Periphery&Core & Normal_Periphery\n",
    "    #df2 N_Periphery\n",
    "    #df3 T_PC\n",
    "\n",
    "    df4 = pd.concat([df2,df3]).reset_index(drop=True) \n",
    "    \n",
    "    # Eliminamos los labels\n",
    "    features = df4.copy()\n",
    "    features = features.drop(['classes'], axis=1)\n",
    "    \n",
    "    #Extraemos los labels\n",
    "    labels = df4.copy()\n",
    "\n",
    "    labels = labels['classes'].values\n",
    "    \n",
    "    return features,labels\n",
    "\n",
    "def load_data_complete_s4(path):\n",
    "    df_complete=pd.read_csv(path)\n",
    "    \n",
    "    # Scenario 4 new: Tumor_Core & Tumor_Periphery & N_Periphery\n",
    "\n",
    "    # Eliminamos los labels\n",
    "    features = df_complete.copy()\n",
    "    features = features.drop(['classes'], axis=1)\n",
    "    \n",
    "    #Extraemos los labels\n",
    "    labels = df_complete.copy()\n",
    "    labels = labels['classes'].values\n",
    "    \n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb6e59",
   "metadata": {},
   "source": [
    "# LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54c579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/DATA_Complete_GBM.csv'\n",
    "\n",
    "featuress1,labelss1=load_data_complete_s1(path)\n",
    "featuress2,labelss2=load_data_complete_s2(path)\n",
    "featuress3,labelss3=load_data_complete_s3(path)\n",
    "featuress4,labelss4=load_data_complete_s4(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65853643",
   "metadata": {},
   "source": [
    "# ML APPLICATION - OBTAINING THE 20 GENES PER MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb7b76c",
   "metadata": {},
   "source": [
    "## Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"originals labels unique: \",np.unique(labelss1, return_counts=True)) \n",
    "X_trains1, X_tests1, y_trains1, y_tests1 = train_test_split(featuress1, labelss1, \n",
    "                                                    test_size=0.20, random_state=21, stratify=labelss1)\n",
    "sampler = ADASYN(random_state=21,n_jobs=-1) \n",
    "print(\"y_train ORIGINAL labels unique:   \",np.unique(y_trains1, return_counts=True))\n",
    "print(\"y_test ORIGINAL labels unique:   \",np.unique(y_tests1, return_counts=True))\n",
    "X_trains1, y_trains1 = sampler.fit_resample(X_trains1, y_trains1)             \n",
    "print(\"y_train labels unique:   \",np.unique(y_trains1, return_counts=True))\n",
    "print(\"y_test labels unique:    \",np.unique(y_tests1, return_counts=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db8f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trains1=csr_matrix(X_trains1)\n",
    "X_tests1=csr_matrix(X_tests1)\n",
    "models1 = XGBClassifier(eval_metric='mlogloss',n_jobs=-1)\n",
    "models1.fit(X_trains1, y_trains1) \n",
    "y_preds1 = models1.predict(X_tests1)\n",
    "accuracy_s1  = accuracy_score(y_tests1,y_preds1) \n",
    "print('accuracy_score: {0:.4f}'.format(accuracy_s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eff179",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=list(featuress1.columns)\n",
    "viz = FeatureImportances(models1,labels=feature_names,topn=20)\n",
    "viz.fit(X_trains1, y_trains1)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e06ca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importances=pd.DataFrame({'features':featuress1.columns,'feature_importance':models1.feature_importances_})\n",
    "feature_importances.sort_values('feature_importance',ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d816cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fi_s1=list(feature_importances.sort_values('feature_importance',ascending=False)[:20]['features'])\n",
    "for i in range(len(fi_s1)):\n",
    "    print(fi_s1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features=featuress1.loc[:,fi]\n",
    "#features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e20d6d2",
   "metadata": {},
   "source": [
    "## Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb5329",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"originals labels unique: \",np.unique(labelss2, return_counts=True)) \n",
    "X_trains2, X_tests2, y_trains2, y_tests2 = train_test_split(featuress2, labelss2, \n",
    "                                                    test_size=0.20, random_state=21, stratify=labelss2)\n",
    "sampler = SVMSMOTE(random_state=8,n_jobs=-1) \n",
    "print(\"y_train ORIGINAL labels unique:   \",np.unique(y_trains2, return_counts=True))\n",
    "print(\"y_test ORIGINAL labels unique:   \",np.unique(y_tests2, return_counts=True))\n",
    "X_trains2, y_trains2 = sampler.fit_resample(X_trains2, y_trains2)             \n",
    "print(\"y_train labels unique:   \",np.unique(y_trains2, return_counts=True))\n",
    "print(\"y_test labels unique:    \",np.unique(y_tests2, return_counts=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a7cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models2 = LogisticRegression(solver='liblinear',n_jobs=-1)\n",
    "models2.fit(X_trains2, y_trains2) \n",
    "y_preds2 = models2.predict(X_tests2)\n",
    "accuracy_s2  = accuracy_score(y_tests2,y_preds2) \n",
    "print('accuracy_score: {0:.4f}'.format(accuracy_s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0076ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = FeatureImportances(models2, topn=20)\n",
    "viz.fit(X_trains2, y_trains2)\n",
    "viz.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2876e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://predictivehacks.com/feature-importance-in-python/\n",
    "#Las de una de las clases\n",
    "feature_importance=pd.DataFrame({'feature':list(featuress2.columns),'feature_importance':[i for i in models2.coef_[0]]})\n",
    "feature_importance.sort_values('feature_importance',ascending=False)[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7fde9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Las de otra de las clases\n",
    "cond1=(feature_importance[\"feature_importance\"]<0)\n",
    "feature_importance[cond1].sort_values('feature_importance',ascending=True)[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc230a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dado que se usa model.coef_ se recomienda usar esta forma con el valor absoluto\n",
    "#Porque los positivos son para una clase, y los negativos para la otra\n",
    "feature_importance=pd.DataFrame({'feature':list(featuress2.columns),'feature_importance':[abs(i) for i in models2.coef_[0]]})\n",
    "feature_importance.sort_values('feature_importance',ascending=False)[:20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7689ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fi_s2=list(feature_importance.sort_values('feature_importance',ascending=False)[:20]['feature'])\n",
    "for i in range(len(fi_s2)):\n",
    "    print(fi_s2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dd1c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features=featuress2.loc[:,fi]\n",
    "#features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9078c73d",
   "metadata": {},
   "source": [
    "## Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd255af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"originals labels unique: \",np.unique(labelss3, return_counts=True)) \n",
    "X_trains3, X_tests3, y_trains3, y_tests3 = train_test_split(featuress3, labelss3, \n",
    "                                                    test_size=0.20, random_state=21, stratify=labelss3)\n",
    "sampler = SMOTE(random_state=21,n_jobs=-1) \n",
    "print(\"y_train ORIGINAL labels unique:   \",np.unique(y_trains3, return_counts=True))\n",
    "print(\"y_test ORIGINAL labels unique:   \",np.unique(y_tests3, return_counts=True))\n",
    "X_trains3, y_trains3 = sampler.fit_resample(X_trains3, y_trains3)             \n",
    "print(\"y_train labels unique:   \",np.unique(y_trains3, return_counts=True))\n",
    "print(\"y_test labels unique:    \",np.unique(y_tests3, return_counts=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c73e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "models3 = GradientBoostingClassifier(random_state=8)\n",
    "models3.fit(X_trains3, y_trains3) \n",
    "y_preds3 = models3.predict(X_tests3)\n",
    "accuracy_s3  = accuracy_score(y_tests3,y_preds3) \n",
    "print('accuracy_score: {0:.4f}'.format(accuracy_s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5635da5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = FeatureImportances(models3, topn=20)\n",
    "viz.fit(X_trains3, y_trains3)\n",
    "viz.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41312caa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importances=pd.DataFrame({'features':featuress3.columns,'feature_importance':models3.feature_importances_})\n",
    "feature_importances.sort_values('feature_importance',ascending=False)[:20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b989233b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fi_s3=list(feature_importances.sort_values('feature_importance',ascending=False)[:20]['features'])\n",
    "for i in range(len(fi_s3)):\n",
    "    print(fi_s3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3d40bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features=featuress3.loc[:,fi]\n",
    "#features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f434e",
   "metadata": {},
   "source": [
    "## Scenario 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df347e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"originals labels unique: \",np.unique(labelss4, return_counts=True)) \n",
    "X_trains4, X_tests4, y_trains4, y_tests4 = train_test_split(featuress4, labelss4, \n",
    "                                                    test_size=0.20, random_state=21, stratify=labelss4)\n",
    "sampler = RandomOverSampler(random_state=21) \n",
    "print(\"y_train ORIGINAL labels unique:   \",np.unique(y_trains4, return_counts=True))\n",
    "print(\"y_test ORIGINAL labels unique:   \",np.unique(y_tests4, return_counts=True))\n",
    "X_trains4, y_trains4 = sampler.fit_resample(X_trains4, y_trains4)             \n",
    "print(\"y_train labels unique:   \",np.unique(y_trains4, return_counts=True))\n",
    "print(\"y_test labels unique:    \",np.unique(y_tests4, return_counts=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31517ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models4 = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=4,\n",
    "                  min_child_weight=4, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                  objective= 'binary:logistic', nthread=4, seed=27, eval_metric='mlogloss', n_jobs=-1)\n",
    "models4.fit(X_trains4, y_trains4) \n",
    "y_preds4 = models4.predict(X_tests4)\n",
    "accuracy_s4  = accuracy_score(y_tests4,y_preds4) \n",
    "print('accuracy_score: {0:.4f}'.format(accuracy_s4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ec9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = FeatureImportances(models4, topn=20)\n",
    "viz.fit(X_trains4, y_trains4)\n",
    "viz.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70860434",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances=pd.DataFrame({'features':featuress4.columns,'feature_importance':models4.feature_importances_})\n",
    "feature_importances.sort_values('feature_importance',ascending=False)[:20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a9221",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_s4=list(feature_importances.sort_values('feature_importance',ascending=False)[:20]['features'])\n",
    "for i in range(len(fi_s4)):\n",
    "    print(fi_s4[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca229aeb",
   "metadata": {},
   "source": [
    "# COMPARING PERFORMANCE WITH DIFFERENT NUMBER OF GENES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e701a1",
   "metadata": {},
   "source": [
    "## 23,368 Genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d15eff",
   "metadata": {},
   "source": [
    "### Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e77973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[XGBClassifier(eval_metric='mlogloss',n_jobs=-1)] \n",
    "class_balance_over_sampling(featuress1, labelss1, HO=True, CV=False, methods_list=[\"ADASYN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da7fe4d",
   "metadata": {},
   "source": [
    "### Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[LogisticRegression(solver='liblinear',n_jobs=-1)] \n",
    "class_balance_over_sampling(featuress2, labelss2, HO=True, CV=False, methods_list=[\"SVMSMOTE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23871e64",
   "metadata": {},
   "source": [
    "### Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab323e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[GradientBoostingClassifier(random_state=8)] \n",
    "class_balance_over_sampling(featuress3, labelss3, HO=True, CV=False, methods_list=[\"SMOTE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72531156",
   "metadata": {},
   "source": [
    "### Scenario 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=4,\n",
    "                  min_child_weight=4, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                  objective= 'binary:logistic', nthread=4, seed=27, eval_metric='mlogloss', n_jobs=-1)] \n",
    "class_balance_over_sampling(featuress4, labelss4, HO=True, CV=False, methods_list=[\"RandomOverSampler\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8bd270",
   "metadata": {},
   "source": [
    "## 20 Genes per ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dec516",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fi_s1),len(fi_s2),len(fi_s3),len(fi_s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc2c55b",
   "metadata": {},
   "source": [
    "### Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83323263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[XGBClassifier(eval_metric='mlogloss',n_jobs=-1)] \n",
    "class_balance_over_sampling(featuress1[fi_s1], labelss1, HO=True, CV=False, methods_list=[\"ADASYN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c3306",
   "metadata": {},
   "source": [
    "### Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af57a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[LogisticRegression(solver='liblinear',n_jobs=-1)] \n",
    "class_balance_over_sampling(featuress2[fi_s2], labelss2, HO=True, CV=False, methods_list=[\"SVMSMOTE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0510312",
   "metadata": {},
   "source": [
    "### Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dabde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[GradientBoostingClassifier(random_state=8)] \n",
    "class_balance_over_sampling(featuress3[fi_s3], labelss3, HO=True, CV=False, methods_list=[\"SMOTE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cecf2c",
   "metadata": {},
   "source": [
    "### Scenario 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319c4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=4,\n",
    "                  min_child_weight=4, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                  objective= 'binary:logistic', nthread=4, seed=27, eval_metric='mlogloss', n_jobs=-1)] \n",
    "class_balance_over_sampling(featuress4[fi_s4], labelss4, HO=True, CV=False, methods_list=[\"RandomOverSampler\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ae9741",
   "metadata": {},
   "source": [
    "## 65 Genes extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f1bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fi_s1),len(fi_s2),len(fi_s3),len(fi_s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fca926",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_s1_ext = fi_s1.copy()\n",
    "fi_s1_ext.extend([element for element in fi_s2 if element not in fi_s1_ext])\n",
    "fi_s1_ext.extend([element for element in fi_s3 if element not in fi_s1_ext])\n",
    "fi_s1_ext.extend([element for element in fi_s4 if element not in fi_s1_ext])\n",
    "len(fi_s1_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c38b92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fi_s1_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bddfd55",
   "metadata": {},
   "source": [
    "### Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f0369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[XGBClassifier(eval_metric='mlogloss',n_jobs=-1)] \n",
    "class_balance_over_sampling(featuress1[fi_s1_ext], labelss1, HO=True, CV=False, methods_list=[\"ADASYN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d643edc",
   "metadata": {},
   "source": [
    "### Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c818f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[LogisticRegression(solver='liblinear',n_jobs=-1)] \n",
    "class_balance_over_sampling(featuress2[fi_s1_ext], labelss2, HO=True, CV=False, methods_list=[\"SVMSMOTE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad563847",
   "metadata": {},
   "source": [
    "### Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be77be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[GradientBoostingClassifier(random_state=8)] \n",
    "class_balance_over_sampling(featuress3[fi_s1_ext], labelss3, HO=True, CV=False, methods_list=[\"SMOTE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6671e6d",
   "metadata": {},
   "source": [
    "### Scenario 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a303ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=4,\n",
    "                  min_child_weight=4, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                  objective= 'binary:logistic', nthread=4, seed=27, eval_metric='mlogloss', n_jobs=-1)] \n",
    "class_balance_over_sampling(featuress4[fi_s1_ext], labelss4, HO=True, CV=False, methods_list=[\"RandomOverSampler\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf76882",
   "metadata": {},
   "source": [
    "## 12 Genes intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcae9b54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(fi_s1+fi_s2+fi_s3+fi_s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_gen_different_sets = list()\n",
    "\n",
    "list_gen_different_sets.append(list(set(fi_s1)&set(fi_s2)))\n",
    "list_gen_different_sets.append(list(set(fi_s1)&set(fi_s3)))\n",
    "list_gen_different_sets.append(list(set(fi_s1)&set(fi_s4)))\n",
    "list_gen_different_sets.append(list(set(fi_s2)&set(fi_s3)))\n",
    "list_gen_different_sets.append(list(set(fi_s2)&set(fi_s4)))\n",
    "list_gen_different_sets.append(list(set(fi_s3)&set(fi_s4)))\n",
    "\n",
    "igen=list()\n",
    "for list_gen in list_gen_different_sets:\n",
    "    for gen in list_gen:\n",
    "        igen.append(gen)\n",
    "\n",
    "igen = list(np.unique(np.array(igen)))\n",
    "igen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c51d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(igen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7706d2b2",
   "metadata": {},
   "source": [
    "### Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8adb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[XGBClassifier(eval_metric='mlogloss',n_jobs=-1)] \n",
    "class_balance_over_sampling(featuress1[igen], labelss1, HO=True, CV=False, methods_list=[\"ADASYN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6373c3a",
   "metadata": {},
   "source": [
    "### Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8565b518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[LogisticRegression(solver='liblinear',n_jobs=-1)] \n",
    "class_balance_over_sampling(featuress2[igen], labelss2, HO=True, CV=False, methods_list=[\"SVMSMOTE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceff8bf",
   "metadata": {},
   "source": [
    "### Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c1fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[GradientBoostingClassifier(random_state=8)] \n",
    "class_balance_over_sampling(featuress3[igen], labelss3, HO=True, CV=False, methods_list=[\"SMOTE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41c916",
   "metadata": {},
   "source": [
    "### Scenario 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19732812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=4,\n",
    "                  min_child_weight=4, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                  objective= 'binary:logistic', nthread=4, seed=27, eval_metric='mlogloss', n_jobs=-1)] \n",
    "class_balance_over_sampling(featuress4[igen], labelss4, HO=True, CV=False, methods_list=[\"RandomOverSampler\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a25d9",
   "metadata": {},
   "source": [
    "## 8 Genes, best selected for each scenario with the best 4 ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d725b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each scenario these are the interesction between the best 4 ML algorithms. \n",
    "# Scenario 1: ATP1A2, SPARCL1, FTL\n",
    "# Scenario 2: EGFR, SPOCK1, ANXA1\n",
    "# Scenario 3: EGFR, APOD\n",
    "# Scenario 4: ATP1A2, APOD, TMSB4X\n",
    "gen8 = [\"ATP1A2\", \"SPARCL1\", \"FTL\", \"EGFR\", \"SPOCK1\", \"ANXA1\", \"APOD\", \"TMSB4X\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0161090d",
   "metadata": {},
   "source": [
    "### Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e832c325",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[XGBClassifier(eval_metric='mlogloss',n_jobs=-1)] \n",
    "class_balance_over_sampling(featuress1[gen8], labelss1, HO=True, CV=False, methods_list=[\"ADASYN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609dc1ca",
   "metadata": {},
   "source": [
    "### Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae392e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[LogisticRegression(solver='liblinear',n_jobs=-1)] \n",
    "class_balance_over_sampling(featuress2[gen8], labelss2, HO=True, CV=False, methods_list=[\"SVMSMOTE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3898892c",
   "metadata": {},
   "source": [
    "### Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d9655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[GradientBoostingClassifier(random_state=8)] \n",
    "class_balance_over_sampling(featuress3[gen8], labelss3, HO=True, CV=False, methods_list=[\"SMOTE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2a118",
   "metadata": {},
   "source": [
    "### Scenario 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1138d14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ML Model\n",
    "classifiers=[XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=4,\n",
    "                  min_child_weight=4, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                  objective= 'binary:logistic', nthread=4, seed=27, eval_metric='mlogloss', n_jobs=-1)] \n",
    "class_balance_over_sampling(featuress4[gen8], labelss4, HO=True, CV=False, methods_list=[\"RandomOverSampler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8340bc72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
